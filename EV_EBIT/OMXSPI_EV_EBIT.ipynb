{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Download financial data of the stocks in OMXSPI (390ish stocks listed in Stockholm) and rank them based on the financial metric EV / EBIT\n",
        "\n",
        "IMPORTANT: I have implemented some measures to avoid rate limitations when downloading data. But, the block labelled 'ev / ebit calculation' will likely have to be run multiple times due to Yahoo Finance FREE API limiting access.\n",
        "\n",
        "The partial results are saved as pkl files each time so it finishes eventually without having to do the same work multiple times.\n",
        "\n",
        "January 2025."
      ],
      "metadata": {
        "id": "zdNymuhGpglw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data."
      ],
      "metadata": {
        "id": "BoT17lSbx8l8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKaY0C2yTjS5",
        "outputId": "0aac7a3d-e150-498e-fb20-5f63191bb4a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today's date: 2025-04-25\n",
            "--2025-04-25 06:58:19--  https://indexes.nasdaqomx.com/Index/ExportWeightings/OMXSPI?tradeDate=2025-04-25T00:00:00.000&timeOfDay=SOD\n",
            "Resolving indexes.nasdaqomx.com (indexes.nasdaqomx.com)... 45.60.150.18\n",
            "Connecting to indexes.nasdaqomx.com (indexes.nasdaqomx.com)|45.60.150.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21446 (21K) [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
            "Saving to: ‘tickers.xlsx’\n",
            "\n",
            "tickers.xlsx        100%[===================>]  20.94K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-04-25 06:58:21 (547 KB/s) - ‘tickers.xlsx’ saved [21446/21446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download ticker data for OMXSPI from Nasdaq OMX\n",
        "\n",
        "# example address:\n",
        "# 'https://indexes.nasdaqomx.com/Index/ExportWeightings/OMXSPI?tradeDate=2025-01-16T00:00:00.000&timeOfDay=SOD'\n",
        "\n",
        "# need to replace '2025-01-16' with todays date in yyyy-mm-dd format.\n",
        "# this ensures that I always have the latest index-components.\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "# Get today's date\n",
        "today = date.today()\n",
        "print(\"Today's date:\", today)\n",
        "\n",
        "# string1 is static part of the HTTP adress\n",
        "# string 2 is dynamically updated.\n",
        "\n",
        "string1 = 'https://indexes.nasdaqomx.com/Index/ExportWeightings/OMXSPI?tradeDate='\n",
        "string2 = str(today) + 'T00:00:00.000&timeOfDay=SOD'\n",
        "http = string1 + string2\n",
        "\n",
        "# the '{http}' makes sure the variable http is being treated as a string.\n",
        "# this make sure there are no problems with special characters.\n",
        "\n",
        "!wget -O tickers.xlsx '{http}'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the ticker file into a Pandas DataFrame\n",
        "df = pd.read_excel(\"tickers.xlsx\", engine=\"openpyxl\")\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "tRINKJa-XsSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tickers = tickers = df['Unnamed: 1'].iloc[1:]   #.iloc[1:] removes first row\n",
        "tickers_l = tickers.tolist() # create list of tickets.\n",
        "print(f' 5 first components of tickers_l: {tickers_l[:5]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8thD0jMIbjUr",
        "outputId": "c9fccb4c-d950-4008-b8e0-95b2faf59169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 5 first components of tickers_l: ['8TRA', 'AAK', 'ABB', 'ACAD', 'ACE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Go from the Security Symbols used by Nasdaq to yahoo finance tickers.\n",
        "# this is necessary because the data is being fetched from Yahoo Finance.\n",
        "\n",
        "def convert_to_yahoo_ticker(name):\n",
        "    # Replace spaces with dashes and append .ST for Stockholm stocks\n",
        "    ticker = name.replace(\" \", \"-\") + \".ST\"\n",
        "    return ticker\n",
        "\n",
        "# Example usage\n",
        "#companies = [\"XANO B\", \"VOLVO B\", \"ERIC B\"]\n",
        "#yahoo_tickers = [convert_to_yahoo_ticker(company) for company in companies]"
      ],
      "metadata": {
        "id": "gouWUpjcwoh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yahoo_tickers = [convert_to_yahoo_ticker(company) for company in tickers_l]\n",
        "yahoo_tickers[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380ad222-8435-47fa-dc1b-1cc01f0a2df2",
        "id": "RZBBitL0woh8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['8TRA.ST', 'AAK.ST', 'ABB.ST', 'ACAD.ST', 'ACE.ST']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the A entry if both A and B stocks are in the list.\n",
        "# for Example, we don't need 'ACRI-A.ST', and 'ACRI-B.ST', get rid of A.\n",
        "\n",
        "# A is usually less liquid so that's the one to get rid of.\n",
        "# Some exceptions exist. SHB B is for example less liquid than\n",
        "# SHB A. But, in general A is the one to get rid of.\n",
        "\n",
        "# Set to keep track of the stocks we want to keep\n",
        "tickers_list = set()\n",
        "\n",
        "# Iterate over each ticker\n",
        "for ticker in yahoo_tickers:\n",
        "    # Check if it's a version A (contains '-A') and see if its B counterpart exists\n",
        "    if '-A' in ticker:\n",
        "        counterpart = ticker.replace('-A', '-B')\n",
        "        if counterpart in yahoo_tickers:\n",
        "            continue  # Skip the A version if the B version exists\n",
        "    # Add to the set if it's not an A version or no B counterpart exists\n",
        "    tickers_list.add(ticker)\n",
        "\n",
        "# Convert the set back to a list (optional)\n",
        "tickers_list = list(tickers_list)\n",
        "\n",
        "print(tickers_list)\n",
        "print(len(tickers_list))"
      ],
      "metadata": {
        "id": "a7klvDu1u_MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EV / EBIT calculation"
      ],
      "metadata": {
        "id": "mM08rfCux_x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This block: compute EV / EBIT for all companies in tickers_list.\n",
        "\n",
        "# This code may need to be ran several times due to rate limitations.\n",
        "\n",
        "# 2 second sleep is implemented in the loop to mitigate the risk of\n",
        "# getting rate limited.\n",
        "\n",
        "# Saving valuations as pickles is implemented to deal with the loop being\n",
        "# broken by rate limitations.\n",
        "\n",
        "\n",
        "import yfinance as yf\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Create directory to save individual valuations\n",
        "os.makedirs(\"valuations\", exist_ok=True)\n",
        "\n",
        "# List of potential debt fields\n",
        "debt_fields = ['Net Debt', 'Total Debt', 'Total Liabilities Net Minority Interest']\n",
        "\n",
        "valuations = {}\n",
        "\n",
        "for ticker in tickers_list:\n",
        "    # Skip if already saved\n",
        "    file_path = f\"valuations/{ticker}.pkl\"\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"Skipping {ticker} — already saved.\")\n",
        "        continue\n",
        "\n",
        "    # Create the Ticker object\n",
        "    company = yf.Ticker(ticker)\n",
        "\n",
        "    # Try to access company.info\n",
        "    sector = company.info.get('sector', None)\n",
        "\n",
        "    # If company.info is missing or 'sector' is unavailable, skip this ticker\n",
        "    if not sector:\n",
        "        print(f\"Skipping {ticker} due to missing 'sector' info.\")\n",
        "        continue\n",
        "\n",
        "    # Exclude financials and RE.\n",
        "    if sector == 'Financial Services' or sector == 'Real Estate':\n",
        "        print('Skipping ticker ', ticker, 'sector: ', sector)\n",
        "        continue\n",
        "\n",
        "    # If the company is not in financials, perform EV / EBIT calculation\n",
        "    try:\n",
        "        MC = company.info['marketCap']\n",
        "    except:\n",
        "        print(f\"Missing market cap for {ticker}\")\n",
        "        continue\n",
        "\n",
        "    net_debt = None\n",
        "\n",
        "    for debt_field in debt_fields:\n",
        "        if debt_field == 'Net Debt':\n",
        "            try:\n",
        "                net_debt_series = company.balance_sheet.loc['Net Debt']\n",
        "                net_debt = net_debt_series.iloc[0]\n",
        "                if net_debt != net_debt:  # check for NaN\n",
        "                    raise KeyError\n",
        "                break\n",
        "            except KeyError:\n",
        "                continue\n",
        "        else:\n",
        "            try:\n",
        "                total_debt_s = company.balance_sheet.loc[debt_field]\n",
        "                total_debt = total_debt_s.iloc[0]\n",
        "                cash_s = company.balance_sheet.loc['Cash And Cash Equivalents']\n",
        "                cash = cash_s.iloc[0]\n",
        "                net_debt = total_debt - cash\n",
        "                break\n",
        "            except KeyError:\n",
        "                continue\n",
        "\n",
        "    if net_debt is None:\n",
        "        print(f\"No valid debt data for {ticker}\")\n",
        "        continue\n",
        "\n",
        "    ev = MC + net_debt\n",
        "\n",
        "    try:\n",
        "        ebit_series = company.income_stmt.loc['EBIT']\n",
        "        ebit = ebit_series.iloc[0]\n",
        "\n",
        "        ev_ebit = ev / ebit\n",
        "        valuations[ticker] = ev_ebit\n",
        "\n",
        "        # Save individual valuation\n",
        "        with open(file_path, 'wb') as f:\n",
        "            pickle.dump(ev_ebit, f)\n",
        "\n",
        "        print(f\"{ticker}: EV/EBIT = {ev_ebit:.2f} — saved.\")\n",
        "\n",
        "    except KeyError:\n",
        "        print('No EBIT data for ticker: ', ticker)\n",
        "        valuations[ticker] = -1\n",
        "\n",
        "    # Delay to avoid rate limiting\n",
        "    time.sleep(2)\n"
      ],
      "metadata": {
        "id": "gVMPHJmHIwv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the valuations\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "valuations = {}  # reset or create new\n",
        "\n",
        "# SET TO YOUR DIRECTORY WHERE 'valuations' WAS SAVED.\n",
        "dataroot = '/content' # root directory in Google Colab\n",
        "\n",
        "# path to the folder where each ticker's valuation as a separate .pkl\n",
        "valuations_folder = os.path.join(dataroot, 'valuations')\n",
        "\n",
        "# creation valuations dict.\n",
        "\n",
        "for filename in os.listdir(valuations_folder):\n",
        "    if filename.endswith(\".pkl\"):\n",
        "        ticker = filename.replace(\".pkl\", \"\")\n",
        "        filepath = os.path.join(valuations_folder, filename)\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            valuation = pickle.load(f)\n",
        "            valuations[ticker] = valuation\n"
      ],
      "metadata": {
        "id": "LiAjssxyPebl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out negative values and then sort in ascending order\n",
        "# treat items as float to avoiding sorting strings (won't work)\n",
        "\n",
        "import math\n",
        "\n",
        "# Filter out NaN values and negative values.\n",
        "# Negative valuations means the company is losing money, this is no good.\n",
        "filtered_valuations = {k: v for k, v in valuations.items() if not math.isnan(v) and v > 0}\n",
        "\n",
        "# Sort the dictionary by value\n",
        "sorted_data = sorted(filtered_valuations.items(), key=lambda item: item[1])\n",
        "\n",
        "# n number of companies to display\n",
        "fraction = 0.10 # 0.10 --> top 10% of companies.\n",
        "n = int(fraction * len(tickers))\n",
        "\n",
        "# Sort the dictionary by the values (EV/EBIT) and then slice the top `n`\n",
        "top_companies = sorted(sorted_data, key=lambda item: item[1])[:n]"
      ],
      "metadata": {
        "id": "cd0fq9qad4fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creat ticker --> company name mapping\n",
        "\n",
        "# Create dictionary from col1 as keys and col2 as values\n",
        "mapping_dict = dict(zip(df['Unnamed: 1'].iloc[1:], df['Unnamed: 0'].iloc[1:]))\n",
        "\n",
        "# convert to yahoo keys.\n",
        "\n",
        "# Create a new dictionary with modified keys\n",
        "yahoo_mapping_dict = {convert_to_yahoo_ticker(key): value for key, value in mapping_dict.items()}"
      ],
      "metadata": {
        "id": "n1sc-aZKoS9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results.\n",
        "\n",
        "\n",
        "print(f'Highest {n} (top {fraction*100} %) ranked non-financial and non-real-estate companies in OMXSPI by EV / EBIT: ', '\\n')\n",
        "\n",
        "for key, value in top_companies:\n",
        "    print(yahoo_mapping_dict[key], ' EV / EBIT:', round(value, 2))"
      ],
      "metadata": {
        "id": "A2FZJX-Rbt9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e408485-cc58-4110-a822-1020919323b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highest 39 (top 10.0 %) ranked non-financial and non-real-estate companies in OMXSPI by EV / EBIT:  \n",
            "\n",
            "Cinclus Pharma Holding AB  EV / EBIT: 0.52\n",
            "Volvo Car AB ser. B  EV / EBIT: 1.49\n",
            "Eniro Group AB  EV / EBIT: 2.23\n",
            "SSAB AB ser. B  EV / EBIT: 2.49\n",
            "Saniona AB  EV / EBIT: 2.74\n",
            "Enea AB  EV / EBIT: 3.63\n",
            "Bong AB  EV / EBIT: 5.09\n",
            "Dedicare AB ser. B  EV / EBIT: 5.33\n",
            "Scandic Hotels Group AB  EV / EBIT: 5.48\n",
            "G5 Entertainment AB  EV / EBIT: 5.77\n",
            "AcadeMedia AB  EV / EBIT: 5.94\n",
            "Bulten AB  EV / EBIT: 6.38\n",
            "ProfilGruppen AB ser. B  EV / EBIT: 6.41\n",
            "NOVOTEK AB ser. B  EV / EBIT: 6.57\n",
            "Nordic Paper Holding AB  EV / EBIT: 6.63\n",
            "Boliden AB  EV / EBIT: 6.67\n",
            "Arctic Paper S.A.  EV / EBIT: 6.77\n",
            "B3 Consulting Group AB  EV / EBIT: 7.01\n",
            "Pricer AB ser. B  EV / EBIT: 7.31\n",
            "Profoto Holding AB  EV / EBIT: 7.39\n",
            "Nilorngruppen AB Ser. B  EV / EBIT: 7.65\n",
            "Green Landscaping Group AB  EV / EBIT: 7.81\n",
            "Humana AB  EV / EBIT: 7.99\n",
            "ATTENDO AB  EV / EBIT: 8.0\n",
            "VBG GROUP AB ser. B  EV / EBIT: 8.38\n",
            "Sleep Cycle AB  EV / EBIT: 8.56\n",
            "SKF, AB ser. B  EV / EBIT: 8.65\n",
            "Ambea AB  EV / EBIT: 8.9\n",
            "Arla Plast AB  EV / EBIT: 8.95\n",
            "Netel Holding AB  EV / EBIT: 8.95\n",
            "Arjo AB ser. B  EV / EBIT: 9.0\n",
            "Arise AB  EV / EBIT: 9.15\n",
            "Proact IT Group AB  EV / EBIT: 9.58\n",
            "Skanska AB ser. B  EV / EBIT: 9.66\n",
            "Stockwik Forvaltning AB  EV / EBIT: 9.73\n",
            "KABE Group AB ser. B  EV / EBIT: 9.76\n",
            "NCC AB ser. B  EV / EBIT: 9.77\n",
            "Transtema AB  EV / EBIT: 9.89\n",
            "HEXPOL AB, ser. B  EV / EBIT: 9.93\n"
          ]
        }
      ]
    }
  ]
}